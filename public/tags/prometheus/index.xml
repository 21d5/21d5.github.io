<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>prometheus on 阳明的博客</title>
    <link>https://www.qikqiak.com/tags/prometheus/</link>
    <description>Recent content in prometheus on 阳明的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.qikqiak.com/tags/prometheus/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus 监控外部 Kubernetes 集群</title>
      <link>https://www.qikqiak.com/post/monitor-external-k8s-on-prometheus/</link>
      <pubDate>Mon, 29 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/monitor-external-k8s-on-prometheus/</guid>
      <description>&lt;p&gt;前面我们的文章中都是将 Prometheus 安装在 Kubernetes 集群中来采集数据，但是在实际环境中很多企业是将 Prometheus 单独部署在集群外部的，甚至直接监控多个 Kubernetes 集群，虽然不推荐这样去做，因为 Prometheus 采集的数据量太大，或大量消耗资源，比较推荐的做法是用不同的 Prometheus 实例监控不同的集群，然后用联邦的方式进行汇总。但是使用 Prometheus 监控外部的 Kubernetes 集群这个需求还是非常有必要的。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>使用 Loki 进行日志监控和报警</title>
      <link>https://www.qikqiak.com/post/use-loki-monitor-alert/</link>
      <pubDate>Sat, 06 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/use-loki-monitor-alert/</guid>
      <description>&lt;p&gt;对于生产环境以及一个有追求的运维人员来说，哪怕是毫秒级别的宕机也是不能容忍的。对基础设施及应用进行适当的日志记录和监控非常有助于解决问题，还可以帮助优化成本和资源，以及帮助检测以后可能会发生的一些问题。前面我们介绍了使用 EFK 技术栈来收集和监控日志，本文我们将使用更加轻量级的 Grafana Loki 来实现日志的监控和报警，一般来说 Grafana Loki 包括3个主要的组件：Promtail、Loki 和 Grafana（简称 PLG），最为关键的是如果你熟悉使用 Prometheus 的话，对于 Loki 的使用也完全没问题，因为他们的使用方法基本一致的，如果是在 Kubernetes 集群中自动发现的还具有相同的 Label 标签。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes HPA 使用详解</title>
      <link>https://www.qikqiak.com/post/k8s-hpa-usage/</link>
      <pubDate>Tue, 07 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/k8s-hpa-usage/</guid>
      <description>&lt;p&gt;在前面的学习中我们使用用一个 &lt;code&gt;kubectl scale&lt;/code&gt; 命令可以来实现 Pod 的扩缩容功能，但是这个毕竟是完全手动操作的，要应对线上的各种复杂情况，我们需要能够做到自动化去感知业务，来自动进行扩缩容。为此，Kubernetes 也为我们提供了这样的一个资源对象：&lt;code&gt;Horizontal Pod Autoscaling（Pod 水平自动伸缩）&lt;/code&gt;，简称&lt;code&gt;HPA&lt;/code&gt;，HPA 通过监控分析一些控制器控制的所有 Pod 的负载变化情况来确定是否需要调整 Pod 的副本数量，这是 HPA 最基本的原理：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.qikqiak.com/k8strain/assets/img/controller/horizontal-pod-autoscaler.svg&#34; alt=&#34;HPA&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们可以简单的通过 &lt;code&gt;kubectl autoscale&lt;/code&gt; 命令来创建一个 HPA 资源对象，&lt;code&gt;HPA Controller&lt;/code&gt;默认&lt;code&gt;30s&lt;/code&gt;轮询一次（可通过 &lt;code&gt;kube-controller-manager&lt;/code&gt; 的&lt;code&gt;--horizontal-pod-autoscaler-sync-period&lt;/code&gt; 参数进行设置），查询指定的资源中的 Pod 资源使用率，并且与创建时设定的值和指标做对比，从而实现自动伸缩的功能。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>用 Kubernetes 资源对象创建 Grafana Dashboard</title>
      <link>https://www.qikqiak.com/post/use-crd-create-grafana-dashboard/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/use-crd-create-grafana-dashboard/</guid>
      <description>&lt;p&gt;我们在使用 Grafana Dashboard 来展示我们的监控图表的时候，很多时候我们都是去找别人已经做好的 Dashboard 拿过来改一改，但是这样也造成了很多使用 Grafana 的人员压根不知道如何去自定义一个 Dashboard，虽然这并不是很困难。这里我们介绍一个比较新颖（骚）的工具：&lt;a href=&#34;https://github.com/K-Phoen/dark&#34;&gt;DARK&lt;/a&gt;，全称 &lt;code&gt;Dashboards As Resources in Kubernetes.&lt;/code&gt;，意思就是通过 Kubernetes 的资源对象来定义 Grafana Dashboard，实现原理也很简单，也就是通过 CRD 来定义 Dashboard，然后通过和 Grafana 的 API Token 进行交互实现 Dashboard 的 CRUD。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AlertManager 何时报警</title>
      <link>https://www.qikqiak.com/post/alertmanager-when-alert/</link>
      <pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/alertmanager-when-alert/</guid>
      <description>&lt;p&gt;在使用 Prometheus 进行监控的时候，通过 AlertManager 来进行告警，但是有很多人对报警的相关配置比较迷糊，不太清楚具体什么时候会进行告警。下面我们来简单介绍下 AlertManager 中的几个容易混淆的参数。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>优秀的 Grafana K8S 插件 - DevOpsProdigy KubeGraf</title>
      <link>https://www.qikqiak.com/post/grafana-k8s-plugin-kubegraf/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/grafana-k8s-plugin-kubegraf/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/devopsprodigy/kubegraf/&#34;&gt;DevOpsProdigy KubeGraf&lt;/a&gt; 是一个非常优秀的 Grafana Kubernetes 插件，是 Grafana 官方的 &lt;a href=&#34;https://grafana.com/plugins/grafana-kubernetes-app&#34;&gt;Kubernetes 插件&lt;/a&gt; 的升级版本，该插件可以用来可视化和分析 Kubernetes 集群的性能，通过各种图形直观的展示了 Kubernetes 集群的主要服务的指标和特征，还可以用于检查应用程序的生命周期和错误日志。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus 记录规则的使用</title>
      <link>https://www.qikqiak.com/post/recording-rules-on-prometheus/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/recording-rules-on-prometheus/</guid>
      <description>&lt;p&gt;Prometheus 作为现在最火的云原生监控工具，它的优秀表现是毋庸置疑的。但是在我们使用过程中，随着时间的推移，存储在 Prometheus 中的监控指标数据越来越多，查询的频率也在不断的增加，当我们用 Grafana 添加更多的 Dashboard 的时候，可能慢慢地会体验到 Grafana 已经无法按时渲染图表，并且偶尔还会出现超时的情况，特别是当我们在长时间汇总大量的指标数据的时候，Prometheus 查询超时的情况可能更多了，这时就需要一种能够类似于后台批处理的机制在后台完成这些复杂运算的计算，对于使用者而言只需要查询这些运算结果即可。Prometheus 提供一种&lt;strong&gt;记录规则（Recording Rule）&lt;/strong&gt; 来支持这种后台计算的方式，可以实现对复杂查询的 PromQL 语句的性能优化，提高查询效率。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus 黑盒监控</title>
      <link>https://www.qikqiak.com/post/blackbox-exporter-on-prometheus/</link>
      <pubDate>Fri, 13 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/blackbox-exporter-on-prometheus/</guid>
      <description>&lt;p&gt;前面我们主要介绍了 Prometheus 下如何进行白盒监控，我们监控主机的资源用量、容器的运行状态、数据库中间件的运行数据、自动发现 Kubernetes 集群中的资源等等，这些都是支持业务和服务的基础设施，通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而从完整的监控逻辑的角度，除了大量的应用白盒监控以外，还应该添加适当的 &lt;code&gt;Blackbox（黑盒）&lt;/code&gt;监控，黑盒监控即以用户的身份测试服务的外部可见性，常见的黑盒监控包括&lt;code&gt;HTTP 探针&lt;/code&gt;、&lt;code&gt;TCP 探针&lt;/code&gt; 等用于检测站点或者服务的可访问性，以及访问效率等。&lt;/p&gt;

&lt;p&gt;黑盒监控相较于白盒监控最大的不同在于黑盒监控是以故障为导向当故障发生时，黑盒监控能快速发现故障，而白盒监控则侧重于主动发现或者预测潜在的问题。一个完善的监控目标是要能够从白盒的角度发现潜在问题，能够在黑盒的角度快速发现已经发生的问题。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/prometheus/blackbox_exporter&#34;&gt;Blackbox Exporter&lt;/a&gt; 是 Prometheus 社区提供的官方黑盒监控解决方案，其允许用户通过：&lt;code&gt;HTTP&lt;/code&gt;、&lt;code&gt;HTTPS&lt;/code&gt;、&lt;code&gt;DNS&lt;/code&gt;、&lt;code&gt;TCP&lt;/code&gt; 以及 &lt;code&gt;ICMP&lt;/code&gt; 的方式对网络进行探测。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>对 Kubernetes 应用进行自定义指标扩缩容</title>
      <link>https://www.qikqiak.com/post/build-k8s-app-with-custom-metrics/</link>
      <pubDate>Fri, 27 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/build-k8s-app-with-custom-metrics/</guid>
      <description>&lt;p&gt;前面我们学习了很多关于 Prometheus 的内容，也学习了 HPA 对象的使用，但是一直没有对自定义指标来对应用进行扩缩容做过讲解，本篇文章我们就来了解下如何通过自定义指标来做应用的动态伸缩功能。当前前提是你需要熟悉 &lt;a href=&#34;https://www.qikqiak.com/tags/kubernetes/&#34;&gt;Kubernetes&lt;/a&gt; 和 &lt;a href=&#34;https://www.qikqiak.com/tags/prometheus/&#34;&gt;Prometheus&lt;/a&gt;，如果不熟悉的话可以查看我们前面的一系列文章，或者直接查看我们的 &lt;a href=&#34;https://www.qikqiak.com/post/promotion-51&#34;&gt;Kubernetes 进阶视频课程&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>《深入浅出Prometheus》</title>
      <link>https://www.qikqiak.com/post/prometheus-book/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-book/</guid>
      <description>&lt;p&gt;千呼万唤始出来，国内第一本全方位讲解&lt;code&gt;Prometheus&lt;/code&gt;的书籍&lt;code&gt;《深入浅出Prometheus》&lt;/code&gt;终于出版了，非常荣幸能和陈晓宇、陈啸两位老师参与本书的编写，这也是我参与的第一本严格意义上的书籍，另外两位老师对于&lt;code&gt;Prometheus&lt;/code&gt;研究的深度让我非常佩服，在编写本书的过程中也学习到了很多专业的知识，特别是关于&lt;code&gt;Prometheus&lt;/code&gt;原理和源码方面的认识，之前都只是局限于应用层面，在了解了原理过后显然可以让我们更加有信心去使用&lt;code&gt;Prometheus&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Helm monitor 插件(附视频)</title>
      <link>https://www.qikqiak.com/post/helm-monitor-plugin/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/helm-monitor-plugin/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.qikqiak.com/post/helm-monitor-plugin/&#34;&gt;&lt;img src=&#34;https://bxdc-static.oss-cn-beijing.aliyuncs.com/images/kmnpRH.jpg&#34; alt=&#34;helm monitor&#34; /&gt;&lt;/a&gt;
使用&lt;code&gt;Helm&lt;/code&gt;可以很方便的部署 Kubernetes 应用，但是如果对于线上的应用部署或者更新后出现了问题，要及时回滚到之前的版本该如何去做呢？当然我们可以手动通过&lt;code&gt;kubectl rollout&lt;/code&gt;去进行控制，但是难免需要手动去操作。今天给大家介绍一个 Helm 的插件 Helm monitro，通过监听 Prometheus 或 ElasticSearch 监控或者日志数据，在发生故障时自动回滚 release。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus 删除数据指标</title>
      <link>https://www.qikqiak.com/post/prometheus-delete-metrics/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-delete-metrics/</guid>
      <description>&lt;p&gt;有的时候我们可能希望从 Prometheus 中删除一些不需要的数据指标，或者只是单纯的想要释放一些磁盘空间。Prometheus 中的时间序列只能通过 HTTP API 来进行管理。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus Operator 高级配置</title>
      <link>https://www.qikqiak.com/post/prometheus-operator-advance/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-operator-advance/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/M47g8E3BHzb6IhLiI1P5oA&#34;&gt;&lt;img src=&#34;https://bxdc-static.oss-cn-beijing.aliyuncs.com/images/goc2kc.jpg&#34; alt=&#34;Prometheus Operator 高级配置&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.qikqiak.com/post/prometheus-operator-monitor-etcd&#34;&gt;上节课我们一起学习了如何在 Prometheus Operator 下面自定义一个监控选项&lt;/a&gt;，以及&lt;a href=&#34;https://www.qikqiak.com/post/prometheus-operator-custom-alert&#34;&gt;自定义报警规则&lt;/a&gt;的使用。那么我们还能够直接使用前面课程中的自动发现功能吗？如果在我们的 Kubernetes 集群中有了很多的 Service/Pod，那么我们都需要一个一个的去建立一个对应的 ServiceMonitor 对象来进行监控吗？这样岂不是又变得麻烦起来了？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus Operator 自定义报警</title>
      <link>https://www.qikqiak.com/post/prometheus-operator-custom-alert/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-operator-custom-alert/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.qikqiak.com/post/prometheus-operator-monitor-etcd&#34;&gt;上篇文章我们介绍了如何自定义一个 ServiceMonitor 对象&lt;/a&gt;，但是如果需要自定义一个报警规则的话呢？又该怎么去做呢？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus Operator 监控 etcd 集群</title>
      <link>https://www.qikqiak.com/post/prometheus-operator-monitor-etcd/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/prometheus-operator-monitor-etcd/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.qikqiak.com/post/first-use-prometheus-operator/&#34;&gt;上节课和大家讲解了 Prometheus Operator 的安装和基本使用方法&lt;/a&gt;，这节课给大家介绍如何在 Prometheus Operator 中添加一个自定义的监控项。&lt;/p&gt;

&lt;p&gt;除了 Kubernetes 集群中的一些资源对象、节点以及组件需要监控，有的时候我们可能还需要根据实际的业务需求去添加自定义的监控项，添加一个自定义监控的步骤也是非常简单的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;第一步建立一个 ServiceMonitor 对象，用于 Prometheus 添加监控项&lt;/li&gt;
&lt;li&gt;第二步为 ServiceMonitor 对象关联 metrics 数据接口的一个 Service 对象&lt;/li&gt;
&lt;li&gt;第三步确保 Service 对象可以正确获取到 metrics 数据&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Grafana 日志聚合工具 Loki</title>
      <link>https://www.qikqiak.com/post/grafana-log-tool-loki/</link>
      <pubDate>Fri, 14 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/grafana-log-tool-loki/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://www.qikqiak.com/img/posts/grafana-loki-cover.png&#34; alt=&#34;&#34; /&gt;
&lt;code&gt;Loki&lt;/code&gt;是 Grafana Labs 团队最新的开源项目，是一个水平可扩展，高可用性，多租户的日志聚合系统。它的设计非常经济高效且易于操作，因为它不会为日志内容编制索引，而是为每个日志流编制一组标签。项目受 Prometheus 启发，官方的介绍就是：&lt;code&gt;Like Prometheus, but for logs.&lt;/code&gt;，类似于 Prometheus 的日志系统。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus Operator 初体验</title>
      <link>https://www.qikqiak.com/post/first-use-prometheus-operator/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/first-use-prometheus-operator/</guid>
      <description>&lt;p&gt;前面的课程中我们学习了&lt;a href=&#34;https://www.qikqiak.com/k8s-book/docs/52.Prometheus%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.html&#34;&gt;用自定义的方式来对 Kubernetes 集群进行监控&lt;/a&gt;，但是还是有一些缺陷，比如 Prometheus、AlertManager 这些组件服务本身的高可用，当然我们也完全可以用自定义的方式来实现这些需求，我们也知道 Prometheus 在代码上就已经对 Kubernetes 有了原生的支持，可以通过服务发现的形式来自动监控集群，因此我们可以使用另外一种更加高级的方式来部署 Prometheus：&lt;code&gt;Operator&lt;/code&gt; 框架。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Grafana 在 Kubernetes 中的使用</title>
      <link>https://www.qikqiak.com/post/grafana-usage-in-k8s/</link>
      <pubDate>Sat, 17 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/grafana-usage-in-k8s/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/ir3shARUPqjyBtDWcuzutQ&#34;&gt;&lt;img src=&#34;https://www.qikqiak.com/img/posts/grafana-cover.png&#34; alt=&#34;grafana in k8s &#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.qikqiak.com/k8s-book/docs/55.%E7%9B%91%E6%8E%A7Kubernetes%E5%B8%B8%E7%94%A8%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1.html&#34;&gt;前面的课程中我们使用 Prometheus 采集了 Kubernetes 集群中的一些监控数据指标&lt;/a&gt;，我们也尝试使用&lt;code&gt;promQL&lt;/code&gt;语句查询出了一些数据，并且在 Prometheus 的 Dashboard 中进行了展示，但是明显可以感觉到 Prometheus 的图表功能相对较弱，所以一般情况下我们会一个第三方的工具来展示这些数据，今天我们要和大家使用到的就是&lt;code&gt;grafana&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>监控 Kubernetes 集群节点</title>
      <link>https://www.qikqiak.com/post/promethues-monitor-k8s-nodes/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/promethues-monitor-k8s-nodes/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/JAOW9Zc8FSPk4xtIXVruag&#34;&gt;&lt;img src=&#34;https://www.qikqiak.com/img/posts/promethus-k8s-node-cover.png&#34; alt=&#34;prometheus monitor k8s node&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.qikqiak.com/post/promethues-monitor-k8s-app/&#34;&gt;上节课我们和大家学习了怎样用 Promethues 来监控 Kubernetes 集群中的应用&lt;/a&gt;，但是对于 Kubernetes 集群本身的监控也是非常重要的，我们需要时时刻刻了解集群的运行状态。&lt;/p&gt;

&lt;p&gt;对于集群的监控一般我们需要考虑以下几个方面：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标&lt;/li&gt;
&lt;li&gt;内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、kubedns/coredns 等组件的详细运行状态&lt;/li&gt;
&lt;li&gt;编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes 应用监控</title>
      <link>https://www.qikqiak.com/post/promethues-monitor-k8s-app/</link>
      <pubDate>Sun, 28 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/promethues-monitor-k8s-app/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/cMy-ApGlIeYKIBnCanwwFQ&#34;&gt;&lt;img src=&#34;https://www.qikqiak.com/img/posts/promethus-k8s-cover.png&#34; alt=&#34;promethues monitor k8s app&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://www.qikqiak.com/k8s-book/docs/52.Prometheus%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.html&#34;&gt;上一节&lt;/a&gt;我们和大家介绍了&lt;code&gt;Prometheus&lt;/code&gt;的数据指标是通过一个公开的 HTTP(S) 数据接口获取到的，我们不需要单独安装监控的 agent，只需要暴露一个 metrics 接口，Prometheus 就会定期去拉取数据；对于一些普通的 HTTP 服务，我们完全可以直接重用这个服务，添加一个&lt;code&gt;/metrics&lt;/code&gt;接口暴露给 Prometheus；而且获取到的指标数据格式是非常易懂的，不需要太高的学习成本。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Prometheus报警AlertManager实战</title>
      <link>https://www.qikqiak.com/post/alertmanager-of-prometheus-in-practice/</link>
      <pubDate>Wed, 27 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/alertmanager-of-prometheus-in-practice/</guid>
      <description>&lt;p&gt;在前面一文&lt;a href=&#34;https://www.qikqiak.com/post/kubernetes-monitor-prometheus-grafana/&#34;&gt;Kubernetes使用Prometheus搭建监控平台&lt;/a&gt;中我们知道了怎么使用&lt;code&gt;Prometheus&lt;/code&gt;来搭建监控平台，也了解了&lt;code&gt;grafana&lt;/code&gt;的使用。这篇文章就来说说报警系统的搭建，有人说报警用&lt;code&gt;grafana&lt;/code&gt;就行了，实际上&lt;code&gt;grafana&lt;/code&gt;对报警的支持真的很弱，而&lt;code&gt;Prometheus&lt;/code&gt;提供的报警系统就强大很多，今天我们的主角就是&lt;code&gt;AlertManager&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes 下升级Prometheus2.0</title>
      <link>https://www.qikqiak.com/post/update-prometheus-2-in-kubernetes/</link>
      <pubDate>Wed, 22 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/update-prometheus-2-in-kubernetes/</guid>
      <description>&lt;p&gt;&lt;code&gt;prometheus&lt;/code&gt;2.0正式版已经发布了，新增了很多特性，特别是底层存储性能提升了不少：&lt;a href=&#34;https://prometheus.io/blog/2017/11/08/announcing-prometheus-2-0/&#34;&gt;https://prometheus.io/blog/2017/11/08/announcing-prometheus-2-0/&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;在将之前监控平台升级到2.0 的过程中还是有一些坑的，因为有很多参数已经更改了，还不清除怎么在&lt;code&gt;kubernetes&lt;/code&gt;上搭建&lt;code&gt;prometheus&lt;/code&gt;监控平台的，可以查看前面的文章&lt;a href=&#34;https://www.qikqiak.com/post/kubernetes-monitor-prometheus-grafana/&#34;&gt;Kubernetes使用Prometheus搭建监控平台&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;本文章中涉及到的&lt;code&gt;yaml&lt;/code&gt;文件可以在&lt;a href=&#34;https://github.com/cnych/k8s-repo/tree/master/prometheus&#34;&gt;github&lt;/a&gt;中查看。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kubernetes使用Prometheus搭建监控平台</title>
      <link>https://www.qikqiak.com/post/kubernetes-monitor-prometheus-grafana/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.qikqiak.com/post/kubernetes-monitor-prometheus-grafana/</guid>
      <description>&lt;p&gt;最近在测试环境搭建了&lt;code&gt;Kubernetes&lt;/code&gt;集群环境，迁移了部分测试环境的应用，由于测试集群性能不是很好，有时会遇到集群资源不够的情况，一般情况下我们是直接通过Dashboard的资源统计图标进行观察的，但是很显然如果要上到生产环境，就需要更自动化的方式来对集群、Pod甚至容器进行监控了。&lt;code&gt;Kubernetes&lt;/code&gt;内置了一套监控方案：influxdb+grafana+heapster。但由于之前我们的应用的业务监控使用的是&lt;code&gt;Prometheus&lt;/code&gt;，所以这里准备使用&lt;code&gt;Prometheus&lt;/code&gt;来完成k8s的集群监控。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>